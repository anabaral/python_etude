# 깨진 글자 내용 찾아보기 1


## 개요

화면에 깨져보이는 문자열이 보였는데 의미는 알 수 없지만 최소한 정보가 유실되지는 않은 느낌이라 뜻을 파악해 보려 하였다.
(깃헙에 붙여넣기 한 아래 문자열은 깨졌을 수 있음)
```
ì´ ìì²­ì ìëµí  ì ììµëë¤.
```

## 절차

먼저 문자열을 복붙하여 텍스트 파일로 저장하였다.

이 화면을 보았던 곳이.. Python 같은 프로그램을 설치 실행하기 까다로운 VDI 환경이라서 
부득이 Powershell을 사용해서 바이트를 수로 변환하였다.
```
PS > Get-Content -Encoding Byte C:\Temp\sso_err_message.txt | Set-Content -Encoding Unknown C:\Temp\temp_new.txt
```

좀더 정제가 가능할 수도 있지만 Powershell은 내게 익숙지 않기에 그냥 단순한 형태로 추출 후 수작업으로 정제해 다음 정수 배열을 얻었다.  
```
[195,172,194,157,194,180,32,195,172,194,154,194,148,195,172,194,178,194,173,195,172,194,
 151,194,144,32,195,172,194,157,194,145,195,171,194,139,194,181,195,173,194,149,32,32,
 195,172,194,136,194,152,32,195,172,194,151,194,134,195,172,194,138,194,181,195,171,194,
 139,194,136,195,171,194,139,194,164,46]
```

느낌상 문장의 마지막이 '다.' 로 끝날 것 같은데 (마지막 46은 마침표) 
'다'의 코드는 b'\xeb\x8b\xa4' = [235,139,164] 이다.

그런데 비교를 해 보니 뭔가 이상한데
- 139, 164는 눈에 뜨이는데 자리는 안맞고 
- 235가 기대되는 숫자는 171이라 안맞고 
- 각기 끼워져 있는 195와 194는 뭐지? 싶음.

그래서 전반적인 패턴을 살펴보니 홀수번째의 수들이 195, 194, 194,  195, 194, 194, ... 식으로 반복되는데, 
이 숫자는 utf-8이나 euc-kr로 디코드시도 시 거의 항상 의미를 알 수 없는 글자가 된다.
그래서 일단은 이 수들을 모두 무시함. (다만 195 다음에 오는 수가 3바이트 글자의 첫 바이트일 것은 짐작) 
그러면 얻는 결과들은 이러한데
```
[172,157,180,  32,  172,154,148,  172,178,173,  172,151,144,
 32,  172,157,145,  171,139,181,  173,149,32,32,
 172,136,152,  32,  172,151,134,  172,138,181,  171,139,136,  171,139,164,  46]
```
그리고 글자들 중 32(스페이스)와 46(마침표)을 제외하곤 모두 한글 3바이트라 짐작한 상태로 확인해 보니 
이상하게도 모든 수들이 64에 해당하는 비트가 없음.
이를테면 172 는 64를 더해야 0xec 로 utf-8 글자의 첫 바이트로 인식될 수 있음. 
그럼 무조건 64를 더해줘야 하나? 하고 좀 시행착오를 해 보니 
3바이트 글자의 첫 바이트에 해당할 만한 수에만 64를 더하면 얼추 문자가 구성되는 걸 확인.
위에서 모두 문자가 되지만 예외적인 게 [173,149,32,32] 인데 
이건 원리는 모르겠으나 [64+173, 149, 128+32](할), [32](스페이스) 로 볼 수 있음. (왜 이번만 128+32 패턴일까? 이건 모르겠음)

아래는 몇 번 시행착오를 거치며 만든 함수
```
def decoded_bytes(bytes_arr):
  bytes_hexarr = [x.to_bytes(1,byteorder='little') for x in bytes_arr]
  bytes = b''.join(bytes_hexarr)
  print(bytes)
  print(bytes.decode('utf8'))
```

이 함수의 사용 예
```
>>> bytes_arr = [64+171, 139, 136]
>>> decoded_bytes(bytes_arr)
b'\xeb\x8b\x88'
니
```

글자 확인해본 바
```
'이'.encode('utf8') --> [64+172,157,180]
'요' --> [64+172, 154, 148]
'청' --> [64+172, 178, 173]
'에' --> [64+172, 151, 144]
'응' --> [64+172, 157, 145]
'답' --> [64+171, 139, 181]
'할'.encode('utf-8')  b'\xed\x95\xa0' = [237, 149, 160] 그런데 32=\x20 과 128의 차이가 남.
'수' --> [236, 136, 152]
'없' --> [64+172, 151, 134]
'습' --> [64+172, 138, 181]
'니' --> [64+171, 139, 136]
'다'.encode('utf8') --> [64+171,139,164]
```

## 

보통 웹화면에서 글자가 깨져보이면 `euc-kr` 에서 `utf-8`로 변환하는 과정에서 깨지는 패턴이었는데
그럴 경우 정보가 유실되어 대개는 살아남은 글자 몇 개를 가지고 추측해야 했었다.

그런데 이번 경우는 정보가 좀 덜 깨진 신기한 경우였다. 어떤 로직으로 오길래 이렇게 깨지는 걸까?

